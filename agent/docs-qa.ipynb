{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install llama-index and llama-parse dependencies\n",
    "\n",
    "Additionally, we'll need to have the llamaCloud API key to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU llama-index llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "path = sys.path[0]+'/.env'\n",
    "load_dotenv(path)\n",
    "\n",
    "os.environ['LLAMA_CLOUD_API_KEY'] = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "inference_api_key = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the sync code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing `LlamaParse` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Parse documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id ab409edf-b99b-4af7-b137-441bf8da9e6d\n",
      "Started parsing the file under job_id 0b94c051-1d1f-4f8b-8f85-b24a368d0bd9\n"
     ]
    }
   ],
   "source": [
    "docs = parser.load_data(['./data/ai-report.pdf', './data/goog-10-k-2023.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the parsed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# OFFICE OF Artificial Intelligence Educational Technology and the Future of Teaching and Learning Insights and Recommendations May 2023\n",
      "---\n",
      "## Artificial Intelligence and the Future of Teaching and Learning\n",
      "\n",
      "Miguel A. Cardona, Ed.D.\n",
      "Secretary, U.S. Department of Education\n",
      "\n",
      "Roberto J. Rodríguez\n",
      "Assistant Secretary, Office of Planning, Evaluation, and Policy Development\n",
      "\n",
      "Kristina Ishmael\n",
      "Deputy Director, Office of Educational Technology\n",
      "\n",
      "May 2023\n",
      "\n",
      "Examples Are Not Endorsements\n",
      "\n",
      "This document contains examples and resource materials that are provided for the user’s convenience. The inclusion of any material is not intended to reflect its importance nor is it intended to endorse any views expressed or products or services offered. These materials may contain the views and recommendations of various subject matter experts as well as hypertext links, contact addresses, and websites to information created and maintained by other public and private organizations. The opinions expressed in any\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549\n",
      "\n",
      "## FORM 10-K\n",
      "\n",
      "(Mark One)\n",
      "\n",
      "☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended December 31, 2023 OR ☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the transition period from to . Commission file number: 001-37580\n",
      "\n",
      "Alphabet Inc. (Exact name of registrant as specified in its charter)\n",
      "\n",
      "Delaware 61-1767919 (State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification No.)\n",
      "\n",
      "1600 Amphitheatre Parkway Mountain View, CA 94043 (Address of principal executive offices, including zip code) (650) 253-0000 (Registrant's telephone number, including area code)\n",
      "\n",
      "|Title of each class|Trading Symbol(s)|Name of each exchange on which registered|\n",
      "|---|---|---|\n",
      "|Class A Common Stock, $0.001 par value|GOOGL|Nasdaq Stock Market LLC (Nasdaq Global Select Market)|\n",
      "|Class C Capital Stock, $0.001 par\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM and embedding model\n",
    "Let's use some opensource llm and embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import Settings\n",
    "# from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
    "# from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "# from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "# # from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Settings.llm = HuggingFaceInferenceAPI(\n",
    "#         model_name=\"HuggingFaceH4/zephyr-7b-alpha\", token=inference_api_key\n",
    "#     )\n",
    "# Settings.embed_model = LangchainEmbedding(HuggingFaceInferenceAPIEmbeddings(\n",
    "#     api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `MarkdownElementNodeParser` to parse markdown objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(llm=OpenAI('gpt-3.5-turbo'), num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents=[docs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "recursive_index = VectorStoreIndex(nodes=base_nodes+objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU llama-index-postprocessor-flag-embedding-reranker git+https://github.com/FlagOpen/FlagEmbedding.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "reranker = FlagEmbeddingReranker(\n",
    "    top_n=5,\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    ")\n",
    "\n",
    "recursive_query_engine = recursive_index.as_query_engine(\n",
    "    similarity_top_k=15,\n",
    "    node_postprocessors=[reranker],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"your question based on context\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
